\documentclass{article}

\usepackage{arxiv}
\usepackage[latin1]{inputenc} %Accentos
\usepackage[spanish,english,es-nolists]{babel} %Castellano
\usepackage[T1]{fontenc}

\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{siunitx}
\usepackage{subfigure}

\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsmath}
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{cleveref}       % smart cross-referencing
\usepackage{lipsum}         % Can be removed after putting your text content
\usepackage{graphicx}
\usepackage[numbers]{natbib} % numbers for arxiv
\usepackage{doi}

\usepackage{algorithm}
\usepackage{algpseudocode}

\usepackage{mathrsfs}  

\title{Redes Generativas Adversarias (GAN) \\ Fundamentos Teóricos y Aplicaciones}

% Here you can change the date presented in the paper title
%\date{September 9, 1985}
% Or remove it
%\date{}

\author{ \href{https://orcid.org/0000-0002-8142-7983}{\includegraphics[scale=0.06]{orcid.pdf}\hspace{1mm}Jordi de la Torre}\thanks{mailto:jordi.delatorre@gmail.com web:jorditg.github.io} \\
	Ph.D. in Computer Science (ML/AI)\\
	Universitat Oberta de Catalunya\\
	Barcelona, ES \\
	\texttt{jordi.delatorre@gmail.com} \\
	%% \AND
	%% Coauthor \\
	%% Affiliation \\
	%% Address \\
	%% \texttt{email} \\
	%% \And
	%% Coauthor \\
	%% Affiliation \\
	%% Address \\
	%% \texttt{email} \\
	%% \And
	%% Coauthor \\
	%% Affiliation \\
	%% Address \\
	%% \texttt{email} \\
}

% Uncomment to override  the `A preprint' in the header
\renewcommand{\headeright}{Survey}
\renewcommand{\undertitle}{Survey}
\renewcommand{\shorttitle}{GANs: Fundamentos Teóricos y Aplicaciones}

%%% Add PDF metadata to help others organize their library
%%% Once the PDF is generated, you can check the metadata with
%%% $ pdfinfo template.pdf
\hypersetup{
pdftitle={GANs: Fundamentos teóricos y Aplicaciones},
pdfsubject={CS.AI},
pdfauthor={Jordi de la Torre},
pdfkeywords={Aprendizaje profundo, GAN, modelos generativos, redes adversarias},
}

\begin{document}
\maketitle

\selectlanguage{spanish} 

\begin{abstract}

Las redes adversarias generativas (GANs) son un método basado en el entrenamiento de dos redes neuronales, una denominada generadora y otra discriminadora, compitiendo entre sí para generar nuevas instancias que se asemejen a las de la distribución de probabilidad de los datos de entrenamiento. Las GANs tienen una amplia gama de aplicaciones en campos como la visión por computadora, la segmentación semántica, la síntesis de series temporales, la edición de imagen, el procesamiento del lenguaje natural y la generación de imagen a partir de texto, entre otros. Los modelos generativos modelizan la distribución de probabilidad de un conjunto de datos, pero en lugar de proporcionar un valor de probabilidad, generan nuevas instancias cercanas a la distribución original. Las GANs utilizan un esquema de aprendizaje que permite codificar los atributos definitorios de la distribución de probabilidad en una red neuronal, lo que permite generar instancias que se asemejen a la distribución de probabilidad original. En este artículo se presentan los fundamentos teóricos de este tipo de redes así como los esquemas básicos de la arquitectura y algunas de sus aplicaciones. Este artículo está en español para facilitar la llegada de este conocimiento científico a la comunidad hispanohablante.

\end{abstract}

\selectlanguage{english}
\begin{abstract}
Generative adversarial networks (GANs) are a method based on the training of two neural networks, one called generator and the other discriminator, competing with each other to generate new instances that resemble those of the probability distribution of the training data. GANs have a wide range of applications in fields such as computer vision, semantic segmentation, time series synthesis, image editing, natural language processing, and image generation from text, among others. Generative models model the probability distribution of a data set, but instead of providing a probability value, they generate new instances that are close to the original distribution. GANs use a learning scheme that allows the defining attributes of the probability distribution to be encoded in a neural network, allowing instances to be generated that resemble the original probability distribution. This article presents the theoretical foundations of this type of network as well as the basic architecture schemes and some of its applications. This article is in Spanish to facilitate the arrival of this scientific knowledge to the Spanish-speaking community.
\end{abstract}

\selectlanguage{spanish} 


% keywords can be removed
\keywords{redes generativas \and GAN \and entrenamiento adversario \and inteligencia artificial \and machine learning}

\newpage

\section{Introducción}

Las redes antagónicas generativas o redes adversarias generativas (GANs) (\cite{goodfellow2020generative}, \cite{creswell2018generative}, \cite{cohen2022generative}) son un método para la optimización competitivo entre dos redes neuronales, una llamada generadora y otra discriminadora, con el objetivo de conseguir generar nuevas instancias idealmente indistinguibles a las pertenecientes a la distribución de probabilidad de la que derivan los datos de entrenamiento.

El fundamento teórico general del que derivan, permite su utilización para la generación de cualquier tipo de datos, habiéndose demostrado efectiva en campos diversos como son la visión por computador (\cite{dziugaite2015training}, \cite{karras2017progressive}, \cite{ledig2017photo}), la segmentación semántica (\cite{luc2016semantic}, \cite{isola2017image}, \cite{wang2018high}, \cite{hoffman2018cycada}), la síntesis de series temporales (\cite{hartmann2018eeg}), la edición de imagen (\cite{shaham2019singan}, \cite{lample2017fader}, \cite{abdal2021styleflow}, \cite{xia2022gan}), el procesamiento del lenguaje natural (\cite{fedus2018maskgan}, \cite{jetchev2016texture}, \cite{guo2018long}), la generación de imagen a partir de texto (\cite{ramesh2021zero}, \cite{radford2021learning}, \cite{patashnik2021styleclip}) entre otros. 

Para cualquier conjunto de datos, podemos hipotetizar que es posible definir una distribución de probabilidad $p_{data}$ representativa de la población representada por la muestra formada por el conjunto de datos. De ser esto posible, para cualquier valor de $\boldsymbol{x}$ será posible establecer un valor $P_{data}(\boldsymbol{x})$ que determine la probabilidad de que $\boldsymbol{x}$ pertenezca a la población. De existir una función de este tipo, sería una función discriminativa que dada una instancia permitiría conocer la probabilidad de pertenencia a la población. Los modelos generativos modelizan la distribución de probabilidad mencionada pero no proporcionan un valor de probabilidad, sino que generan instancias nuevas que pertenecen a distribuciones de probabilidad próximas a la que pretenden asemejar. Las GANs definen un esquema de aprendizaje que facilita la codificación de los atributos definitorios de la distribución de probabilidad en una red neuronal de manera que la red incorpore la información esencial que le permite generar instancias pertenecientes a distribuciones de probabilidad próximas a la que el conjunto de datos que pretende representar.

En la siguiente sección se presenta el esquema básico de la arquitectura GAN y su aspecto distintivo, la naturaleza de la función objetivo utilizada para su optimización. Posteriormente, se presentan las arquitecturas y funciones de objetivo derivadas, así como sus aplicaciones.

\section{El concepto de redes antagónicas}

La arquitectura GAN está formada por dos redes neuronales constituyentes: una denominada discriminadora ($D$) y otra generadora $G$. La red $G$ se encarga de generar nuevas instancias del mismo dominio que el del conjunto de datos de origen. La red $D$ se encarga de discriminar si los datos de entrada son reales, esto es pertenecientes al conjunto de datos de entrada o bien son ficticios, esto es generados artificialmente. Ambas redes se entrenan de manera conjunta de manera que $G$ maximice sus posibilidades de no ser detectada por $D$ y $D$ de forma que haga cada vez más sofisticados sus métodos de detección de los datos generados artificialmente por $G$. Estas dos redes adversarias compiten en un juego de suma cero en el que se hipotetiza que eventualmente llegan a un equilibrio de Nash \cite{moghadam2021game}.

\begin{figure}[ht!]
	\centering
	\includegraphics[width=\textwidth]{figs/gan.pdf}
	\label{fig:gan}
	\caption{Diagrama representativo del proceso de entrenamiento de las redes adversarias generativas (GANs)}
	% \vspace{-5pt}\peufigura{Fuente: \url{http://www.ibmbigdatahub.com/infographic/four-vs-big-data}}
\end{figure}

En la figura \ref{fig:gan} se muestra un diagrama representativo del proceso de optimización de las GAN. Un vector $\boldsymbol{z}$ es muestreo de una distribución de probabilidad aleatoria $p_z$, $\boldsymbol{z} \sim p_z$ y alimentado como entrada a $G$. El propósito de la optimización es conseguir que $G(\boldsymbol{z}) \sim p_g$ acabe siendo una estimación de la distribución de probabilidad $P_{data}$. Las GAN se optimizan la función min-max de un juego de suma cero expresado por la ecuación \ref{eq:loss-gan}.

\begin{equation}
	\min_G \max_D \mathbb{E}_{x \sim p_r} \log[D(\boldsymbol{x})] + \mathbb{E}_{\boldsymbol{z} \sim p_{\boldsymbol{z}}} \log [1 - D(G(\boldsymbol{z}))]	
	\label{eq:loss-gan}
\end{equation}

Equivalentemente, sean $p_\theta$, $D_{\omega}$ las redes neuronales generadora y discriminadora de una GAN, siendo $\theta$ los parámetros de $G$ y $\omega$ los de $D$. Ambas redes se optimizan en conjunto con la función objetivo definida por la ecuación \ref{eq:loss-gan-v2}.

\begin{equation}
	\min_{\theta} \max_{\omega} \mathbb{E}_{x \sim Q} \log[D_{\omega}(x)] + \mathbb{E}_{x \sim p_\theta} \log [1 - D_{\omega}(x))]	
	\label{eq:loss-gan-v2}
\end{equation}

%
%La finalidad de la red generadora, como su nombre indica, %será generar nuevas instancias, mientras que la función de %la discriminadora será identificar si una instancia %ecuación \ref{eq:loss-gan} muestra la función de %optimización a resolver para las dos redes adversarias.
%

Durante el proceso de optimización la red $D$ recibirá como entrada de manera aleatoria datos pertenecientes al conjunto de datos y otros procedentes de la red $G$. Se optimizará su funcionamiento para que su discriminación sea efectiva (ecuación \ref{eq:gradient-discriminator}).

\begin{equation}
	\nabla_{\theta_D} \frac{1}{m}\sum\limits_{i=1}^m[\log D(\boldsymbol{x}^{(i)}) + \log(1-D(G(\boldsymbol{z}^{(i)})))]	
	\label{eq:gradient-discriminator}
\end{equation}

Al mismo tiempo, cuando $D$ reciba una entrada procedente de $G$, éste se optimizará para mejorar sus predicciones y hacer cada vez más difícil el papel de $D$. Esto únicamente se puede conseguir mejorando la calidad de los datos generados y haciéndolos más parecidos al conjunto de datos original (ecuación \ref{eq:gradient-generator}). 

\begin{equation}
	\nabla_{\theta_G}\frac{1}{m}\sum\limits_{i=1}^m \log(1-D(G(\boldsymbol{z}^{(i)})))
	\label{eq:gradient-generator}
\end{equation}

Se establece así una competición entre las dos redes (de ahí el nombre de adversarias) de forma que idealmente en el progreso de este proceso ambas mejoran su funcionamiento al punto que idealmente el generador acaba produciendo datos cada vez más parecidos a los del conjunto de datos original.

\section{Ventajas e inconvenientes de las GAN}

Desde su introducción en 2014, las GANs han despertado un gran interés sobre todo en el campo de la generación de imagen. Esto ha sido debido a que presentan una serie de ventajas sobre el otro paradigma dominante hasta el momento en lo que a modelos generativos se refiere, los VAEs \cite{kingma2013auto}. Dichas ventajas son las siguientes:

\begin{itemize}
	\item \textbf{Imágenes más nítidas}: Las GANs producen imágenes más nítidas que otros modelos generativos disponibles hasta el momento. Los modelos de difusión que veremos más adelante son una excepción posterior en este aspecto.
	\item \textbf{Tamañno configurable}: El tamaño de la variable aleatoria no está restringido pudiéndose enriquecer en caso de ser necesario.
	\item \textbf{Generador versátil}: El paradigma de diseño basado en GANs soporta distintos tipos de funciones generadoras, a diferencia de otros modelos generativos que pueden tener restricciones debido a su arquitectura. Los VAEs, por ejemplo, obligan a utilizar una función Gaussiana en la primera capa del Generador.
\end{itemize}

La arquitectura también tiene sus desventajas entre las que están las siguientes:

\begin{itemize}
	\item \textbf{Colapso de modo}: Durante el entrenamiento sincronizado de generador y discriminador, el generador puede tener tendencia a reproducir únicamente un modo específico que es capaz de burlar al discriminador. A pesar de que este patrón puede estar minimizando la función objetivo, lo hace sin cubrir todo el dominio del conjunto de datos.
	\item \textbf{Desvanecimiento de gradientes}: A veces el discriminador se optimiza demasiado rápido en su función. En estos casos, los gradientes que propaga pueden ser demasiado bajos para asegurar la optimización del generador.
	\item \textbf{Inestabilidad}: A menudo durante el entrenamiento los parámetros de ambas redes fluctúan sin encontrar un punto de equilibrio. En estas circunstancias el generador tiene dificultades en encontrar un punto que genere imágenes de alta calidad.
\end{itemize}

\section{Arquitecturas derivadas}

En esta sección se presentan aquellas arquitecturas derivadas de la original que mejoran su rendimiento en alguna de las desventajas mencionadas.

\subsection{GAN semi-supervisada (SGAN)}

SGAN \cite{odena2016semi} incluye una variación en el discriminador que le permite aprovechar las ventajas de contar con datos supervisados. Consiste en añadir un cabezal adicional para la predicción de la clase de pertenencia. En aquellos casos reales que se conoce dicha clase, se utiliza el cabezal softmax de predicción para optimizar al discriminador. En aquellos que no se conozca, se utiliza la optimización vía clasificación binaria típica de la GAN convencional. Los resultados demuestran que este tipo de entrenamiento mejora las capacidades de SGAN respecto a la GAN original.

\subsection{Conditional GAN (CGAN)}

CGAN \cite{mirza2014conditional} modifica el método original introduciendo una entrada adicional tanto en el generador como en el discriminador. Esta entrada adicional sirve como condicionante para ambas funciones. Esta nueva información $y$ se fusiona en el generador con el muestreo de la variable aleatoria $z$ para posteriormente generar la nuevas instancias. Lo mismo ocurre en el discriminador donde $y$ se integra con los datos $x$ a analizar. La nueva función de optimización queda como indica la ecuación \ref{eq:loss-cgan}.

\begin{equation}
	\min_G \max_D \mathbb{E}_{x \sim p_r} \log[D(\boldsymbol{x | y})] + \mathbb{E}_{\boldsymbol{z} \sim p_{\boldsymbol{z}}} \log [1 - D(G(\boldsymbol{z | y}))]	
	\label{eq:loss-cgan}
\end{equation}

\subsection{Red antagónica generativa convolucional profunda (DCGAN)}

Las redes antagónicas generativas convolucionales profundas (DCGAN) fueron introducidas por primera vez en \cite{radford2015unsupervised} como método para la generación de imágenes. Utilizan convoluciones en el discriminador y convoluciones traspuestas \cite{dumoulin2016guide} en el generador. Además de mejoras en la resolución de las imágenes generadas, consiguen mejoras en la estabilidad del entrenamiento que en su estudio atribuyen a la introducción de las siguientes modificaciones:

\begin{itemize}
	\item Sustitución de todas las capas de \textit{pooling} de las dos redes. En el discriminador se utilizan núcleos con \textit{stride} mayor que 1 y en el generador convoluciones traspuestas para aumentar el tamaño de la imagen.
	\item Uso de la normalización por lotes en las dos redes.
	\item En el discriminador se cambia la función de activación de ReLU a LeakyReLU \cite{maas2013rectifier}. En el generador se utilizan ReLU en todas las capas excepto en la última donde se usa la función de activación tangente hiperbólica (tanh).
\end{itemize}

\subsection{Progressive GAN (PROGAN)}

En \cite{karras2017progressive} se introduce un método progresivo de entrenamiento y aumento de la resolución de las imágenes generadas que da muy buenos resultados. Muchas de las arquitecturas GAN más exitosas usan este método. En el trabajo citado se empieza entrenando una red generativa de 4x4 para ir añadiendo capas en el generador y discriminador conforme va avanzando el entrenamiento hasta conseguir resoluciones de salida de 1024x1024. Conforme se van añadiendo capas, todas las capas anteriores siguen estando sometidas a los cambios inherentes a la optimización de las redes.

\subsection{Self-attention GAN (SAGAN)}

Muchas de las implementaciones existentes hasta el momento fallan en la captura de patrones geométricos y estructurales de largo alcance. Se hipotetiza que la causa de esto es debida a la naturaleza convolucional de las arquitecturas generativas. Debido a ella, las dependencias son de corto alcance y requieren del paso a través de varias capas para ser resueltas. Existen diversas soluciones que se pueden aplicar para solucionar este aspecto. La primera sería aumentar el tamaño de las convoluciones con el aumento asociado de los requerimientos computacionales. Otra sería el incremento de la profundidad de las redes. Una tercera posibilidad, que es la propuesta por SAGAN \cite{zhang2019self} es la utilización de mecanismos de auto-atención en alguna de las capas de la red convolucional.

Los atributos de salida $\boldsymbol{x} \in \mathbb{R}^{C \times N}$ de una capa de la red neuronal se transforman en dos espacios $\boldsymbol{f}(\boldsymbol{x}) = \boldsymbol{W}_f\boldsymbol{x}$ y $\boldsymbol{g}(\boldsymbol{x}) = \boldsymbol{W}_g\boldsymbol{x}$ para posteriormente calcular la atención como indica la ecuación \ref{eq:att-sagan}.

\begin{equation}
	\beta_{j,i} = \frac{\exp(s_{i,j})}{\sum\limits_{i=1}^N \exp(s_{i,j})} \quad \text{ donde } \quad s_{i,j} = \boldsymbol{f}(\boldsymbol{x}_i)^T \boldsymbol{g}(\boldsymbol{x}_j) 	
	\label{eq:att-sagan}
\end{equation}

$\beta_{j,i}$ indica la atención que está prestando a la región $i$ cuando está generando la $j$. $C$ es el número de canales y $N$ el número de atributos de la anterior capa. La salida de la capa de atención $\boldsymbol{o} = (\boldsymbol{o}_1, \boldsymbol{o}_2, ... \boldsymbol{o}_N) \in \mathbb{R}^{C \times N}$ se puede expresar como indica la ecuación \ref{eq:out-att-sagan}.

\begin{equation}
	\boldsymbol{o}_j = \boldsymbol{v} \Big( \sum\limits_{i=1}^N \beta_{j,i} \boldsymbol{h}(\boldsymbol{x}_i)\Big) \text{ , } \boldsymbol{h}(\boldsymbol{x}_i) = \boldsymbol{W}_h \boldsymbol{x}_i \text{ , } \boldsymbol{v}(\boldsymbol{x}_i) = \boldsymbol{W}_v \boldsymbol{x}_i
	\label{eq:out-att-sagan}
\end{equation}

Donde $\boldsymbol{W}_g \in \mathbb{R}^{\bar{C} \times C}$, $\boldsymbol{W}_f \in \mathbb{R}^{\bar{C} \times C}$, $\boldsymbol{W}_h \in \mathbb{R}^{\bar{C} \times C}$ y $\boldsymbol{W}_v \in \mathbb{R}^{C \times \bar{C}}$ son matrices optimizadas en tiempo de entrenamiento, implementadas como convoluciones 1x1. En el artículo se fija $\bar{C} = C/8$ por ser más eficiente de cara a la computación y, según se indica, no afectar significativamente a los resultados.

El valor de auto-atención considerado se escala y se suma al valor del atributo de entrada, $\boldsymbol{y}_i = \gamma \boldsymbol{o}_i + \boldsymbol{x}_i$ siendo $\gamma$ un parámetro optimizable que se inicializa a cero. Esto tiene su lógica pues al inicio del entrenamiento se puede esperar resolver las dependencias locales para que una vez avanzada la optimización se afine resolviendo las dependencias de mayor alcance. Este mecanismo de atención se aplica tanto al generador como al discriminador. Ambos son optimizados minimizando una versión modificada de la función de optimización original, que toma la forma de la ecuación \ref{eq:loss-gan-hinge}. Esta ecuación es la versión de máximo-margen (Hinge Loss) típica para la optimización de SVMs \cite{crammer2001algorithmic}.


\begin{equation}
	\begin{array}{c}
		L_D = - \mathbb{E}_{(x,y) \sim P_{data}} [ \min(0, -1 + D(x,y))] - \mathbb{E}_{z \sim p_z, y \sim P_{data}}[\min(0,-1-D(G(z), y))] \\
		L_G = - \mathbb{E}_{z \sim p_z, y \sim P_{data}}G(G(z),y)
	\end{array}
	\label{eq:loss-gan-hinge}
\end{equation}

Junto con su propuesta presentan también una metodología de entrenamiento para estabilizar el inherentemente inestable proceso de optimización de las GANs.

\subsection{BigGAN}

BigGAN \cite{brock2018large} es un tipo de GAN diseñada para la generación, mediante escalado, de imágenes de alta resolución. Incluye una serie de cambios incrementales respecto a las redes anteriormente mencionadas así como también algunas innovaciones.

Entre las mejoras incrementales de relevancia encontramos las siguientes:

\begin{enumerate}
	\item Propuesta de arquitectura basada en SAGAN utilizando normalización espectral \cite{miyato2018spectral} tanto para $D$ como para $G$ y utilizando TTUR \cite{heusel2017gans}.
	\item Al igual que SAGAN utiliza la función de pérdida Hinge como objetivo de optimización
	\item Utiliza normalización por lotes condicionada a la clase (CBN) \cite{de2017modulating} (mediante proyección lineal)  para proveer de información de la clase a $G$.
	\item Utiliza un discriminador por proyección \cite{miyato2018cgans} para incorporar la información de la clase.
\end{enumerate}

En cuanto a las innovaciones resaltar:

\begin{enumerate}
	\item Incremento del tamaño de los lotes.
	\item Incremento del tamaño de capa.
	\item Adición de conexiones directas entre la variable latente $z$ y las capas intermedias de la red.
	\item Uso de una variante de regularización ortogonal 
	\cite{brock2016neural}.
\end{enumerate}

BigGAN consigue una mejora sustancial de la calidad de las imágenes generadas para tamaños de 128x128, 256x256 y 512x512, aumentando el número de parámetros (x4) y incrementando el tamaño del batch de entrenamiento (x8) respecto a SAGAN. Además de las modificaciones indicadas, introducen algunos cambios sobre las variables latentes, durante el proceso de inferencia consistentes en truncar los valores fuera de un rango determinado.

\subsection{StyleGAN}

StyleGAN \cite{karras2019style} propone una nueva arquitectura para el generador, manteniendo el mismo diseño para el discriminador. En la figura \ref{fig:stylegan} se muestra un esquema de la arquitectura propuesta para la red generadora. 

\begin{figure}[ht!]
	\centering
	\includegraphics[width=0.5\textwidth]{figs/StyleGAN.drawio-925x1024.png}
	\label{fig:stylegan}
	\caption{Diagrama de la arquitectura StyleGAN. Fuente: \url{https://github.com/christianversloot/machine-learning-articles/blob/main/stylegan-a-step-by-step-introduction.md}}
\end{figure}

StyleGAN tiene tres componentes característicos: 

\begin{enumerate}
	\item Crecimiento progresivo del tamaño de la imagen generada al estilo de PROGAN (bloques en amarillo) ($4\times 4 \rightarrow 8 \times 8 \rightarrow 16\times 16 \rightarrow 32\times 32 \rightarrow 64\times 64 \rightarrow 128\times 128 \rightarrow 256\times 256 \rightarrow 512\times 512 \rightarrow 1024 \times 1024$)
	\item En los bloques de Upsample utiliza muestreo bilinear en vez de la copia del valor de los vecinos cercanos.
	\item Sustitución del vector de entrada $z \sim P_z$ por una matriz de entrada constante de $4 \times 4 \times 512$ y se introduce una red de ruido gaussiano, que alimenta independientemente a cada una de las capas intermedias.
	\item Introducción de la denominada \textit{Red de mapeo del ruido}, que al paso por varias capas completamente conectadas, transforma una entrada aleatoria en una representación interna de los estilos. La salida de esta red actúa como entrada en los bloques AdaIN de cada capa fijando los parámetros de sesgo y escalado del bloque con la finalidad de actuar como estilos adaptativos. 
	\item AdaIN. Normalización adaptativa de las instancias: Introducida inicialmente en \cite{huang2017arbitrary}. StyleGAN la utiliza tanto como capa de normalización como para establecer el estilo a través de los parámetros de escalado y sesgo que son derivados de las representaciones internas aprendidas por la red de mapeo de ruido.
\end{enumerate}	


% Batch Norm vs Instance norm vs Adaptative inst norm

\section{f-GAN una generalización de las GANs}

En las secciones previas, hemos presentado a las GANs como una herramienta para generar datos, que se optimiza para producir resultados que se parezcan a los datos de entrenamiento. Se ha explicado cómo este proceso se lleva a cabo a través de la optimización de un modelo parametrizable en forma de red neuronal, midiendo la diferencia entre la distribución del modelo y la real durante el proceso de entrenamiento.

En este apartado, exploraremos cómo distintas formas de medir esta distancia pueden dar lugar a diferentes funciones objetivo y, por lo tanto, a distintas redes resultantes. Este concepto se ha formalizado en el artículo \cite{nowozin2016f}, que proporciona una generalización del concepto de distancia en GANs para diferentes formas de medir la distancia entre distribuciones de probabilidad.


\subsection{Introducción}

Un modelo probabilístico es una representación formal que describe un evento o fenómeno en términos de una distribución de probabilidad, en lugar de proporcionar una respuesta única como lo hacen los modelos deterministas. Estos modelos se utilizan para modelar procesos estocásticos, donde los resultados no están determinados de antemano y pueden variar con el tiempo o en función de las condiciones.

Cuando los principios que rigen un fenómeno son desconocidos o es demasiado complejo describirlos de manera computacionalmente eficiente, una forma de aproximar la solución es modelar su distribución de probabilidad a partir de muestras recopiladas del entorno. De esta manera, se pueden hacer predicciones y tomar decisiones basadas en una comprensión probabilística del fenómeno en cuestión.

\subsection{Estimación de modelos probabilísticos}

Suponiendo que existe una distribución de probabilidad real $Q$, se puede utilizar un modelo paramétrico $P$ para aproximar a $Q$. Para evaluar la validez de nuestro modelo debemos tener un medio de evaluar las diferencias entre ambas distribuciones. Sabemos que ambas variables son estocásticas, esto es, no están definidas por un único valor comparable sino que son distribuciones (funciones). Debemos disponer, por tanto, de una medida que nos permita comparar funciones. Una forma de hacer esto es realizar una abstracción del concepto de distancia para generalizarlo, no únicamente para medir distancias entre puntos, sino también para identificar distancias entre distribuciones de probabilidad. Para facilitar el proceso, puede ser necesario hacer algún tipo de suposición sobre $P$, como que su muestreo sea manejable, de cara a asegurar que las muestras del modelo sean comparables con las muestras reales; que $P$ tenga un gradiente manejable con respecto al muestreo de cara a poder utilizar técnicas de optimización y, finalmente, que tenga una función de probabilidad manejable de forma que pueda calcularse la probabilidad punto a punto.

\subsection{GANs como modelos probabilísticos}

Como ya sabemos, las GANs usan una combinación de dos redes neuronales para crear un modelo generativo con el objetivo de aprender a imitar una distribución real. El generador, como su nombre indica, genera una muestra modelo a partir de un vector aleatorio mediante el uso de una transformación determinista. El discriminador recibe muestras pertenecientes a la distribución real escogidas al azar y del modelo de generación y se entrena para diferenciarlas. Ambas redes están entrenadas de manera adversaria, una para generar imágenes lo más cercanas posible a la distribución real y la otra para detectar las muestras procedentes del generador. Aunque las GAN no proporcionan un valor de probabilidad de la imagen generada, es de esperar que este valor, aunque no sea conocido, exista.

\subsection{Distancia entre distribuciones de probabilidad}

Existen diferentes enfoques para definir la distancia entre las distribuciones de probabilidad. Podemos diferenciar principalmente entre tres enfoques diferentes:

\begin{enumerate}
	\item Métricas de probabilidad integral
	\item Reglas para puntuación
	\item f-divergencias
\end{enumerate}

\subsubsection{\textbf{Métricas de probabilidad integral}}

Abordado por primera vez en las publicación \cite{sriperumbudur2010hilbert}, el punto clave de este método es que ambas distribuciones aparecen en forma de expectativa, lo que permite aproximarse a dicho valor mediante muestreo. La distancia de Wasserstein se deriva de estos métodos, y luego se usó con éxito como una distancia en Wasserstein-GAN \cite{arjovsky2017wasserstein}.

\subsubsection{\textbf{Reglas para puntuación}}

En \cite{gneiting2007strictly} se propuso el enfoque de utilizar una puntuación para evaluar la adecuación de una distribución a otra. El punto es la optimización de la puntuación. La puntuación máxima se logra cuando ambas distribuciones son iguales.

\subsubsection{\textbf{f-divergencias}}

Abordado por primera vez en \cite{ali1966general}, las distribuciones $P$ y $Q$ se requieren en forma de función de densidad. Las f-divergencias son una generalización de la divergencia Kullback-Leiber \cite{kullback1951information}. La expectativa de la distribución $Q$ se multiplica por una función convexa de la relación de verosimilitud entre $P$ y $Q$. Por lo general, no se aplica directamente porque normalmente no se dispone de la distribución de los datos de forma explícita.

En \cite{nguyen2010estimating}, \cite{reid2011information} y en \cite{goodfellow2020generative} se desarrollaron métodos para usar f-divergencias en problemas donde $P$ tiene forma de distribución y $Q$ tiene forma de expectativa y también donde ambas distribuciones tienen forma de expectativa. Esto permitió el uso de tales métricas en problemas donde solo se encuentran disponibles muestras de ambas distribuciones.

Matemáticamente, podemos definir la f-divergencia, denotada como $D_f(P\mid \mid Q)$, como la distancia entre dos distribuciones de probabilidad $P$ y $Q$ que se puede calcular mediante la ecuación \ref{eq:f-divergencia}.

\begin{equation}
	D_f(Q \mid \mid P) = \int_{\mathscr{X}} p(\boldsymbol{x}) f \left( \frac{q(x)}{p(\boldsymbol{x})} \right) dx
	\label{eq:f-divergencia}
\end{equation}

donde $f$ es una función convexa, denominada función generador (nada que ver con el generador de las GANs), que cumple la propiedad $f(1) = 0$, esto es, que en aquellos puntos donde las dos funciones son iguales la distancia es cero. 

La distancia siempre es ser mayor que 0 y es únicamente igual a cero cuando las dos distribuciones coinciden en todo el dominio $\mathscr{X}$.

\begin{table}[ht!]
	\centering
\scalebox{0.8}{
	\begin{tabular}{ l | c | c }
			\hline %\rowcolor[gray]{0.8}
			%% header
			Nombre                     & $ D_f(P \mid \mid Q) $                 & Generador $ f(u) $ \\
			\hline 
			Total variation           & $\frac{1}{2}\int \mid p(\boldsymbol{x})-q(x)\mid dx$         & $\frac{1}{2}\mid u-1 \mid$    \\
			\hline
			Kullback-Leibler         & $\int p(\boldsymbol{x}) \log \frac{p(\boldsymbol{x})}{q(x)}dx $            & $ u \log u $   \\
			\hline
			Reverse Kulback-Leibler  & $\int q(x) \log \frac{q(x)}{p(\boldsymbol{x})}dx $            & $ - \log u $  \\
			\hline
			Pearson $\chi^2$       & $\int \frac{(q(x)-p(\boldsymbol{x}))^2}{p(\boldsymbol{x})}dx$             & $ (u-1)^2 $  \\
			\hline
			Neyman $\chi^2$        & $\int \frac{(p(\boldsymbol{x})-q(x))^2}{q(x)}dx$             & $ \frac{(1-u)^2}{u} $  \\
			\hline
			Squared Hellinger        & $\int (\sqrt{p(\boldsymbol{x})}-\sqrt{q(x)})^2 dx$           & $ (\sqrt{u}-1)^2 $  \\
			\hline
			Jeffrey                  & $\int (p(\boldsymbol{x}) - q(x))\log \left(\frac{p(\boldsymbol{x})}{q(x)}\right)dx)$ & $ (u-1) \log u $  \\
			\hline
			Jensen-Shannon           & $\frac{1}{2}\int p(\boldsymbol{x}) \log \frac{2p(\boldsymbol{x})}{p(\boldsymbol{x})+q(x)} + q(x) \log \frac{2q(x)}{p(\boldsymbol{x})+q(x)} dx$ & $-(u+1)\log \frac{1+u}{2} + u \log u$  \\
			\hline
			Jensen-Shannon weighted  & $\int p(\boldsymbol{x}) \pi \log \frac{p(\boldsymbol{x})}{\pi p(\boldsymbol{x})+(1-\pi)q(x)} + (1-\pi)q(x) \log \frac{q(x)}{\pi p(\boldsymbol{x})+ (1-\pi) q(x)} dx$ & $\pi u \log u + (1 - \pi + \pi u) \log (1 - \pi + \pi u)$  \\
			\hline
			GAN                      & $\int p(\boldsymbol{x}) \log \frac{2p(\boldsymbol{x})}{p(\boldsymbol{x})+q(x)} + q(x) \log \frac{2q(x)}{p(\boldsymbol{x})+q(x)} dx - \log 4 $& $u \log u - (u+1) \log (u+1)$  \\
			\hline
			$\alpha$-divergence    & $ \frac{1}{\alpha (\alpha - 1)} \int \left(p(\boldsymbol{x}) \left[\left(\frac{q(x)}{p(\boldsymbol{x})}\right)^{\alpha} - 1\right] - \alpha (q(x) - p(\boldsymbol{x}))\right)dx $ & $ \frac{1}{\alpha (\alpha - 1)} ( u^{\alpha} - 1 - \alpha(u-1)) $  \\
			\hline
		\end{tabular}
	}
	\label{table:f-divergencias}
	\caption{f-divergencias y generador asociado. Formas distintas de medir la distancia entre dos distribuciones de probabilidad $P$ y $Q$}
\end{table}

\subsubsection{\textbf{Estimación de las f-divergencias mediante muestreo}}

En \cite{nguyen2010estimating} se deriva un método variacional general para estimar las f-divergencias a partir del muestreo de las distribuciones $P$ y $Q$.

Del análisis de funciones convexas sabemos que toda función convexa $f$ tiene un conjugado de Fenchel $f^*$ para el que se cumple que $ f(u) = \displaystyle\sup_{t \in dom_{f^*}} \{ tu - f^* (t) \} $, esto es, que cualquier función convexa puede ser representada como un conjunto de máximos puntuales de funciones lineales. Siendo $ f^*(t) $ el punto de intercepción con el eje de $y$ para cada punto $t$.

\begin{equation*}
	D_f(Q \mid \mid P) = \int_{\mathscr{X}} p(\boldsymbol{x}) f ( \frac{q(x)}{p(\boldsymbol{x})} ) dx \ge 
\end{equation*}

\begin{equation*}
	\ge \displaystyle\sup_{T \in \mathscr{T}} ( \int_{\mathscr{x}} q(x)T(x)dx - \int_{\mathscr{X}}p(\boldsymbol{x})f^*(T(x))dx) = 
\end{equation*}

\begin{equation}
	= \sup_{T \in \mathscr{T}}\left( \mathbb{E}_{x \sim Q}[T(x)] -  \mathbb{E}_{x \sim P}[f^*(T(x))]\right)
	\label{eq:variational-f-divergence}
\end{equation}

Las expresiones pueden ser convertidas a expectativas y utilizadas en un algoritmo de muestreo. Un punto a tener en cuenta es que para algunas divergencias, $ f^* $ únicamente está definido para un dominio restringido. En esos casos, antes de utilizar la función objetivo, debe ser mapeada al dominio donde está definida.

\subsubsection{Función variacional asociada al discriminador}

En el artículo introductorio de las GAN \cite{goodfellow2020generative} se demuestra que la optimización propuesta para la función de pérdida (eq. \ref{eq:loss-gan-v2}) es equivalente a minimizar la divergencia de Jensen-Shanon.

Comparando la expresión de la ecuación \ref{eq:variational-f-divergence} con la función objetivo de GAN vemos que $ T(x) = log(D_{\omega}(x)) $. Confirmamos pues que la GAN original minimiza la divergencia Jensen-Shanon, una caso particular de la f-GAN.

\subsection{Conclusión}

En esta sección se ha generalizado el concepto de medida de la distancia entre distribuciones de probabilidad, utilizado en la función de pérdida de las GAN, para poderlo usar en un contexto más general con cualquier f-divergencia para la medida de la distancia entre la distribución de probabilidad del modelo y la original. En este contexto más general, se ha demostrado que la GAN original es un caso particular de optimización que utiliza la f-divergencia de Jensen-Shanon para la medida de la distancia entre distribuciones. Cualquiera de las medidas alternativas presentadas da lugar a optimizaciones equivalentes, a pesar de ser distintas, desde un punto de vista representativo.

\subsection{Funciones de optimización mejoradas}

En la anterior sección hemos introducido el concepto de f-divergencia para generalizar el concepto de distancia entre distribuciones y hemos nombrado otros métodos alternativos como las métricas de probabilidad integral. En esta sección presentaremos las opciones de optimización que en la práctica han demostrado ser más efectivas para mejorar los problemas relacionados con la optimización min-max original, esto es, el colapso de modo y el desvanecimiento de gradientes. Los objetivos presentados a parte de remediar estos aspectos también mejora la calidad de las imágenes generadas.

\subsubsection{Wasserstein GAN (WGAN)}

WGAN \cite{arjovsky2017wasserstein} resuelve el problema del desvanecimiento de gradientes y colapso de modo reemplazando la optimización de la f-divergencia de Jensen Shanon mediante el uso de la métrica de probabilidad integral EM (Earth mover distance \cite{hitchcock1941distribution}) también llamada distancia de Wasserstein. La ecuación \ref{eq:wasserstein-distance} muestra la ecuación que la define.

\begin{equation}
	W(p_r, p_g) = \inf\limits_{\gamma \in \prod(p_r, p_g)} \mathbb{E}_{(x,y) \sim \gamma} [||x-y||]
	\label{eq:wasserstein-distance}
\end{equation}

donde $\prod(p_r, p_g)$ representa en conjunto de todas las distribuciones conjuntas $\gamma(x,y)$ cuyos marginales son $p_r$ y $p_g$. La distancia EM representa el mínimo coste necesario para transportar la "masa" de $p_r$ a $p_g$ para conseguir hacerlas iguales.

Las f-divergencias como KL y JS muestran problemas de inestabilidad cuando $p_r$ y $p_g$ están muy alejadas una de otra. EM es estable también en estos casos, además de ser continua, hecho que facilita la derivación de gradientes útiles para llevar a cabo la optimización. Un inconveniente es que el ínfimo de la ecuación \ref{eq:wasserstein-distance} es intratable. Por esa razón los autores de WGAN estiman el coste de EM con la ecuación  \ref{eq:wasserstein-distance-tractable}.

\begin{equation}
	W(p_r, p_g) \approx \max\limits_{w \sim \mathscr{W}} \mathbb{E}_{\boldsymbol{x} \sim p_r} [f_w(\boldsymbol{x})] - \mathbb{E}_{\boldsymbol{z} \sim p_z}[f_w(G(\boldsymbol{z}))]
	\label{eq:wasserstein-distance-tractable}
\end{equation}

donde ${f_w}_{w \in \mathscr{W}}$ es una familia de funciones paramétricas que son K-Lipschitz para algún $K(||f||_L) \le K)$.

Los autores proponen encontrar la mejor función $f_w$ que maximiza la eq. \ref{eq:wasserstein-distance-tractable} propagando el gradiente $\mathbb{E}_{\boldsymbol{z} \sim p_z}[f_w(G(\boldsymbol{z}))]$, donde $g_\theta$ es el generador $g$ con parámetros $\theta$. $f_w$ puede ser representada por $D$ pero condicionada a ser K-Lipschitz. $w$ en $f_w$ representa a los parámetros de $D$ y el objetivo de $D$ es maximizar \ref{eq:wasserstein-distance-tractable}, que aproxima la distancia EM. Cuando $D$ es óptimo, \ref{eq:wasserstein-distance-tractable} se aproxima a la distancia EM real y $G$ se optimiza para minimizar la ecuación \ref{eq:wasserstein-distance-tractable-part2}.

\begin{equation}
	- \min\limits_{G} \mathbb{E}_{\boldsymbol{z} \sim p_z}[f_w(G(\boldsymbol{z}))]
	\label{eq:wasserstein-distance-tractable-part2}
\end{equation}

WGAN suele tener unos gradientes más suaves y medibles en todo el dominio que otras f-divergencias y aprende mejor incluso cuando no está produciendo aún buenas imágenes.

\subsubsection{GAN auto-supervisada (SSGAN)}

SSGAN \cite{chen2019self} utiliza un sistema similar a la CGAN \cite{mirza2014conditional} pero sin la necesidad de contar con etiquetado explícito. Además introduce un nuevo elemento en la función de pérdida, el objetivo del cual es prever el valor de una clase que se deriva directamente de la naturaleza de la imagen analizada. Concretamente, los autores predicen la rotación de la imagen de 4 posibles valores. Este valor es conocido y calculable sin necesidad de etiquetar las imágenes y se demuestra útil para mejorar las capacidades predictivas del discriminador, así como para aprender representaciones útiles para la generación. La nueva función de pérdida tiene la forma indicada en la ecuación \ref{eq:ssgan-loss}.

\begin{equation}
	\begin{array}{c}
		L_G = -V(G,D) - \alpha \mathbb{E}_{\boldsymbol{x} \sim p_G} \mathbb{E}_{r \sim \mathbb{R}}[\log Q_D(R=r \mid \boldsymbol{x}^r)]\\
		L_D = -V(G,D) - \beta \mathbb{E}_{\boldsymbol{x} \sim p_{data}} \mathbb{E}_{r \sim \mathbb{R}}[\log Q_D(R=r \mid \boldsymbol{x}^r)]
	\end{array}
	\label{eq:ssgan-loss}
\end{equation}

donde V(G,D) es el objetivo general de la GAN original (ecuación \ref{eq:loss-gan}), $P_{data}$ y $P_G$ son las distribuciones real y del generador respectivamente, $r \in \mathbb{R}$ es la rotación seleccionada entre los ángulos permitidos ($R = \{0, 90, 180, 270\}$). Una imagen rotada $r$ grados se denota como $\boldsymbol{x}^r$ y $Q(R\mid \boldsymbol{x}^r)$ es la distribución predicha sobre los ángulos de rotación de la muestra. Esta función de pérdida fuerza a aprender representaciones internas de la rotación de forma supervisada hipotetizando que dichas representaciones serán útiles también para la generalización de las capacidades generativas de la GAN. SSGAN obtiene resultados comparables a los de CGAN sin la necesidad de etiquetado externo.

\subsubsection{Normalización espectral (SNGAN)}

En SNGAN \cite{miyato2018spectral} se propone el uso de normalización de los parámetros como medio de estabilización del entrenamiento del discriminador. Es una técnica que es computacionalmente eficiente y que puede ser aplicada de manera sencilla. Sabemos que si $D$ es una función k-Lipshitz , esto es, intuitivamente, que es una función continua sin variaciones abruptas, esto puede servir para estabilizar el entrenamiento de las GAN. SNGAN controla el valor de la constante de Lipschitz limitando la norma espectral de cada capa, normalizando la matriz de pesos de cada capa $W$ para satisfacer la restricción $\sigma(W)=1$ (esto es, que el mayor valor singular de la matriz de pesos sea 1). Esto se consigue simplemente normalizando cada capa mediante la ecuación \ref{eq:spectral-normalization}.

\begin{equation}
	\bar{\boldsymbol{W}}_{SN}(\boldsymbol{W}) = \frac{\boldsymbol{W}}{\sigma(\boldsymbol{W})}
	\label{eq:spectral-normalization}
\end{equation}

donde $\boldsymbol{W}$ representa a la matriz de pesos de cada capa. En el artículo citado se demuestra que esta operación hace que la constante de Lipschitz en el discriminador quede limitada a un máximo de 1, hecho que facilita la optimización.

SNGAN consigue mejoras importantes de los resultados comparado con las técnicas previas de estabilización del entrenamiento publicadas, entre las que se incluyen el recorte del valor de los pesos \cite{arjovsky2017wasserstein}, la penalización de gradientes \cite{wu2019gp}, \cite{mescheder2018training}, normalización batch \cite{ioffe2015batch}, normalización de pesos \cite{salimans2016weight}, normalización de capas \cite{lei2016layer} y regularización ortonormal \cite{brock2016neural}.

\subsubsection{SphereGAN}

SphereGAN \cite{park2020spheregan} es una GAN que utiliza métrica de probabilidad integral (IPM) que usa una hiperesfera para ligar la IPM a la función objetivo y de esta forma mejorar la estabilidad del entrenamiento. La función objetivo utilizada es la indicada en la ecuación \ref{eq:spheragan-loss}.

\begin{equation}
	\min\limits_G \max\limits_D \sum\limits_r \mathbb{E}_x[d_s^r(\boldsymbol{N}, D(\boldsymbol{x}))] - \sum\limits_r \mathbb{E}_z[d_s^r(\boldsymbol{N}, D(G(\boldsymbol{z})))]
	\label{eq:spheragan-loss}
\end{equation}

para $r = 1, ..., R$ donde $d_s^r$ mide la distancia con momento $r$ entre cada muestra y el polo norte de la hiperesfera, $\boldsymbol{N}$. El subíndice $s$ indica que $d_s^r$ está definido en $\mathbb{S}^n$.

Esta propuesta mejora a las anteriores funciones objetivo basadas en la distancia Wasserstein gracias a la definición de los IPM en la hiperesfera. Esto le permite prescindir de muchas de las restricciones que deben ser impuestas a $D$ para asegurar un entrenamiento estable en las anteriores propuestas, como las restricciones sobre la naturaleza Lischitz de las funciones requeridas por la distancia Wasserstein.

El funcionamiento de SphereGAN se podría describir de la forma siguiente: la red $G$ genera datos a partir de un vector aleatorio $z$. Imágenes reales y otras las procedentes de $G$ se alimentan a la red discriminadora $D$ que, a diferencia de las propuestas anteriores, da como resultado un vector de dimensión $n$. SphereGAN re-mapea este vector en una hiper-esfera de n dimensiones utilizando transformaciones geométricas. Los puntos mapeados se utilizan para calcular los momentos geométricos centrados en el polo norte ($\boldsymbol{N}$) de dicha hiper-esfera. La red discriminadora intenta maximizar las diferencias de momento entre las imágenes reales y las falsas, mientras que la generadora intenta conseguir lo contrario.

\section{Una aplicación de las GAN: aumento de datos}

El aumento de datos es una técnica habitual para mejorar el entrenamiento de los modelos en aquellas circunstancias donde se dispone de pocos datos. Podríamos decir que las circunstancias más habituales que requieren aumento de datos serían las siguientes:

\begin{itemize}
	\item \textbf{Etiquetado limitado}: Disponer de pocos datos etiquetados.
	\item \textbf{Diversidad limitada}: Cuando el conjunto de entrenamiento falta variedad en los datos.
	\item \textbf{Datos restringidos}: Alguna de la información es sensible y no puede utilizarse directamente.
\end{itemize}

Los dos primeros casos se pueden resolver manualmente, poniendo recursos para etiquetar más datos, pero puede suponer un coste elevado. Una alternativa para el primer caso consiste en utilizar GANs para aumentar la cantidad de datos. SGAN, por ejemplo, permite generar nuevos datos anotados. El segundo caso es más habitual, pues suele ser habitual disponer de conjuntos de datos con clases desbalanceadas pobres en las clases raras.

\section{Conclusiones}

En este capítulo hemos introducido a las GAN como método para la generación de datos. Es un tipo de arquitectura especialmente estudiada en el campo de generación de imagen. Es un tipo de arquitectura con mucho potencial que tiene algunos problemas sobre todo relacionados con la estabilidad en el entrenamiento. En este capítulo hemos estudiado el diseño original, sus ventajas e inconvenientes así como algunas modificaciones destinadas a solventar los problemas de la propuesta original. Si bien hemos intentado describir los puntos que consideramos clave, el campo en cuestión es muy amplio, tanto en arquitecturas, como en aplicaciones. Este capítulo debe servir como punto de partida para complementarlo con la bibliografía citada así como con las futuras aportaciones.


\newpage
\bibliographystyle{unsrtnat}
\bibliography{generativos}  %%% Uncomment this line and comment out the ``thebibliography'' section below to use the external .bib file (using bibtex) .

\end{document}
